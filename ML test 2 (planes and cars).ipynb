{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML test 2 (planes and cars)","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1xnD9-l5pq6OPgBlUY54OvhTxyTht3Mzr","authorship_tag":"ABX9TyNblgbZeaJYIIsOsBRrqHim"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"v3HrgOXzPCDA","colab_type":"code","outputId":"3752e3d9-7dc8-403d-afa9-ae6c65013bcf","executionInfo":{"status":"ok","timestamp":1582429516596,"user_tz":0,"elapsed":231378,"user":{"displayName":"Giles Billenness","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcSh_UVvHR4Bkj3v8M_6HXbEMW2CdHL9XqNWjpbQ=s64","userId":"01010524810359179053"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["# importing libraries \n","from keras.preprocessing.image import ImageDataGenerator \n","from keras.models import Sequential \n","from keras.layers import Conv2D, MaxPooling2D \n","from keras.layers import Activation, Dropout, Flatten, Dense \n","from keras import backend as K \n","\n","img_width, img_height = 224, 224\n","\n","train_data_dir = 'drive/My Drive/Hackathon/v_data/train'\n","validation_data_dir = 'drive/My Drive/Hackathon/v_data/test'\n","nb_train_samples = 400\n","nb_validation_samples = 100\n","epochs = 10\n","batch_size = 16\n","\n","if K.image_data_format() == 'channels_first': \n","\tinput_shape = (3, img_width, img_height) \n","else: \n","\tinput_shape = (img_width, img_height, 3) \n","\n","# define model archniechure\n","model = Sequential() \n","model.add(Conv2D(32, (2, 2), input_shape = input_shape)) \n","model.add(Activation('relu')) \n","model.add(MaxPooling2D(pool_size =(2, 2))) \n","\n","model.add(Conv2D(32, (2, 2))) \n","model.add(Activation('relu')) \n","model.add(MaxPooling2D(pool_size =(2, 2))) \n","\n","model.add(Conv2D(64, (2, 2))) \n","model.add(Activation('relu')) \n","model.add(MaxPooling2D(pool_size =(2, 2))) \n","\n","model.add(Flatten()) \n","model.add(Dense(64)) \n","model.add(Activation('relu')) \n","model.add(Dropout(0.5)) \n","model.add(Dense(1)) \n","model.add(Activation('sigmoid')) \n","\n","model.compile(loss ='binary_crossentropy', \n","\t\t\t\t\toptimizer ='rmsprop', \n","\t\t\t\tmetrics =['accuracy']) \n","# end model spec\n","\n","train_datagen = ImageDataGenerator( \n","\t\t\t\trescale = 1. / 255, \n","\t\t\t\tshear_range = 0.2, \n","\t\t\t\tzoom_range = 0.2, \n","\t\t\thorizontal_flip = True) \n","\n","test_datagen = ImageDataGenerator(rescale = 1. / 255) \n","\n","train_generator = train_datagen.flow_from_directory(train_data_dir, \n","\t\t\t\t\t\t\ttarget_size =(img_width, img_height), \n","\t\t\t\t\tbatch_size = batch_size, class_mode ='binary') \n","\n","validation_generator = test_datagen.flow_from_directory( \n","\t\t\t\t\t\t\t\t\tvalidation_data_dir, \n","\t\t\t\ttarget_size =(img_width, img_height), \n","\t\tbatch_size = batch_size, class_mode ='binary') \n","\n","model.fit_generator(train_generator, \n","\tsteps_per_epoch = nb_train_samples // batch_size, \n","\tepochs = epochs, validation_data = validation_generator, \n","\tvalidation_steps = nb_validation_samples // batch_size) \n","\n","model.save_weights('model_saved.h5') "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 400 images belonging to 2 classes.\n","Found 100 images belonging to 2 classes.\n","Epoch 1/10\n","25/25 [==============================] - 25s 984ms/step - loss: 1.1600 - acc: 0.5850 - val_loss: 0.4306 - val_acc: 0.9271\n","Epoch 2/10\n","25/25 [==============================] - 23s 906ms/step - loss: 0.6804 - acc: 0.7425 - val_loss: 0.3992 - val_acc: 0.9167\n","Epoch 3/10\n","25/25 [==============================] - 23s 909ms/step - loss: 0.4433 - acc: 0.8150 - val_loss: 0.2591 - val_acc: 0.9048\n","Epoch 4/10\n","25/25 [==============================] - 23s 919ms/step - loss: 0.4657 - acc: 0.7925 - val_loss: 0.3127 - val_acc: 0.9048\n","Epoch 5/10\n","25/25 [==============================] - 23s 915ms/step - loss: 0.3597 - acc: 0.8700 - val_loss: 0.2148 - val_acc: 0.9048\n","Epoch 6/10\n","25/25 [==============================] - 23s 903ms/step - loss: 0.4222 - acc: 0.8525 - val_loss: 0.2600 - val_acc: 0.9048\n","Epoch 7/10\n","25/25 [==============================] - 23s 909ms/step - loss: 0.4137 - acc: 0.8550 - val_loss: 0.2886 - val_acc: 0.9167\n","Epoch 8/10\n","25/25 [==============================] - 23s 926ms/step - loss: 0.2995 - acc: 0.8875 - val_loss: 0.3710 - val_acc: 0.8333\n","Epoch 9/10\n","25/25 [==============================] - 23s 904ms/step - loss: 0.3396 - acc: 0.8675 - val_loss: 0.2552 - val_acc: 0.9167\n","Epoch 10/10\n","25/25 [==============================] - 23s 922ms/step - loss: 0.3102 - acc: 0.8700 - val_loss: 0.2913 - val_acc: 0.8810\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ug8UHUaJd-0u","colab_type":"code","outputId":"cf05d059-0d01-42c9-9514-818bd67265e0","executionInfo":{"status":"ok","timestamp":1582429714168,"user_tz":0,"elapsed":596,"user":{"displayName":"Giles Billenness","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcSh_UVvHR4Bkj3v8M_6HXbEMW2CdHL9XqNWjpbQ=s64","userId":"01010524810359179053"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["from keras.preprocessing import image\n","import numpy as np\n","# from keras.models import load_model\n","# testmodel = create\n","# model = load_model('model_saved.h5')\n","\n","# predicting images\n","img = image.load_img('drive/My Drive/Hackathon/test1.jpg', target_size=(img_width, img_height))\n","img\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/test2.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/test3.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","# ----------------------------------------------------\n","# # predicting multiple images at once\n","# img = image.load_img('test2.jpg', target_size=(img_width, img_height))\n","# y = image.img_to_array(img)\n","# y = np.expand_dims(y, axis=0)\n","\n","# # pass the list of multiple images np.vstack()\n","# images = np.vstack([x, y])\n","# classes = model.predict_classes(images, batch_size=10)\n","\n","# # print the classes, the images belong to\n","# print classes\n","# print classes[0]\n","# print classes[0][0]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0]]\n","[[1]]\n","[[1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H0Yd8cOY0_19","colab_type":"code","colab":{}},"source":["# RESIZE IMAGES BLOCK - FROM REG_IMG folder\n","import PIL\n","from PIL import Image\n","import os\n","# specify large img location\n","directory = 'drive/My Drive/Hackathon/cats&dogs/TEST_TEST_DOGS/big/'\n","baseheight = 255\n","wsize = 255\n","for filename in os.listdir(directory):\n","      img = Image.open(directory+filename)\n","      # # hpercent = (baseheight / float(img.size[1]))\n","      # # wsize = int((float(img.size[0]) * float(hpercent)))\n","      img = img.resize((wsize, baseheight), PIL.Image.ANTIALIAS)\n","      # specify resize img location\n","      img.save('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_DOGS/small/'+filename)#+' new.png')\n","      continue"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MExam6ySrTYv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f8d4b765-4bee-4ac6-d8c1-7c5dd04e52f8","executionInfo":{"status":"ok","timestamp":1582462094253,"user_tz":0,"elapsed":227535,"user":{"displayName":"Giles Billenness","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcSh_UVvHR4Bkj3v8M_6HXbEMW2CdHL9XqNWjpbQ=s64","userId":"01010524810359179053"}}},"source":["# MEME MODEL\n","# \n","# \n","# importing libraries \n","from keras.preprocessing.image import ImageDataGenerator \n","from keras.models import Sequential \n","from keras.layers import Conv2D, MaxPooling2D \n","from keras.layers import Activation, Dropout, Flatten, Dense \n","from keras import backend as K \n","\n","\n","\n","img_width, img_height = 224, 224\n","\n","train_data_dir = 'drive/My Drive/Hackathon/cats&dogs/train'\n","validation_data_dir = 'drive/My Drive/Hackathon/cats&dogs/test'\n","nb_train_samples = 400\n","nb_validation_samples = 100\n","epochs = 10\n","batch_size = 16\n","\n","if K.image_data_format() == 'channels_first': \n","\tinput_shape = (3, img_width, img_height) \n","else: \n","\tinput_shape = (img_width, img_height, 3) \n","\n","# define model archniechure\n","model = Sequential() \n","model.add(Conv2D(32, (2, 2), input_shape = input_shape)) \n","model.add(Activation('relu')) \n","model.add(MaxPooling2D(pool_size =(2, 2))) \n","\n","model.add(Conv2D(32, (2, 2))) \n","model.add(Activation('relu')) \n","model.add(MaxPooling2D(pool_size =(2, 2))) \n","\n","model.add(Conv2D(64, (2, 2))) \n","model.add(Activation('relu')) \n","model.add(MaxPooling2D(pool_size =(2, 2))) \n","\n","model.add(Flatten()) \n","model.add(Dense(64)) \n","model.add(Activation('relu')) \n","model.add(Dropout(0.5)) \n","model.add(Dense(1)) \n","model.add(Activation('sigmoid')) \n","\n","model.compile(loss ='binary_crossentropy', \n","\t\t\t\t\toptimizer ='rmsprop', \n","\t\t\t\tmetrics =['accuracy']) \n","\n","train_datagen = ImageDataGenerator( \n","\t\t\t\trescale = 1. / 255, \n","\t\t\t\tshear_range = 0.2, \n","\t\t\t\tzoom_range = 0.2, \n","\t\t\thorizontal_flip = True) \n","\n","test_datagen = ImageDataGenerator(rescale = 1. / 255) \n","\n","train_generator = train_datagen.flow_from_directory(train_data_dir, \n","\t\t\t\t\t\t\ttarget_size =(img_width, img_height), \n","\t\t\t\t\tbatch_size = batch_size, class_mode ='binary') \n","\n","validation_generator = test_datagen.flow_from_directory( \n","\t\t\t\t\t\t\t\t\tvalidation_data_dir, \n","\t\t\t\ttarget_size =(img_width, img_height), \n","\t\tbatch_size = batch_size, class_mode ='binary') \n","\n","model.fit_generator(train_generator, \n","\tsteps_per_epoch = nb_train_samples // batch_size, \n","\tepochs = epochs, validation_data = validation_generator, \n","\tvalidation_steps = nb_validation_samples // batch_size) \n","\n","model.save_weights('model_saved_catsvsdogs.h5') "],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Found 1072 images belonging to 2 classes.\n","Found 200 images belonging to 2 classes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/10\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","25/25 [==============================] - 25s 1s/step - loss: 0.7719 - acc: 0.5325 - val_loss: 0.6888 - val_acc: 0.4792\n","Epoch 2/10\n","25/25 [==============================] - 22s 882ms/step - loss: 0.7073 - acc: 0.5400 - val_loss: 0.6790 - val_acc: 0.5208\n","Epoch 3/10\n","25/25 [==============================] - 22s 884ms/step - loss: 0.6983 - acc: 0.5150 - val_loss: 0.6601 - val_acc: 0.5568\n","Epoch 4/10\n","25/25 [==============================] - 22s 882ms/step - loss: 0.7001 - acc: 0.6075 - val_loss: 0.6706 - val_acc: 0.5104\n","Epoch 5/10\n","25/25 [==============================] - 22s 877ms/step - loss: 0.6669 - acc: 0.5825 - val_loss: 0.6238 - val_acc: 0.5795\n","Epoch 6/10\n","25/25 [==============================] - 22s 887ms/step - loss: 0.6740 - acc: 0.6025 - val_loss: 0.6376 - val_acc: 0.5729\n","Epoch 7/10\n","25/25 [==============================] - 22s 891ms/step - loss: 0.6712 - acc: 0.6275 - val_loss: 0.6681 - val_acc: 0.5795\n","Epoch 8/10\n","25/25 [==============================] - 20s 819ms/step - loss: 0.6689 - acc: 0.6150 - val_loss: 0.6479 - val_acc: 0.5521\n","Epoch 9/10\n","25/25 [==============================] - 24s 956ms/step - loss: 0.6332 - acc: 0.6850 - val_loss: 0.6090 - val_acc: 0.7273\n","Epoch 10/10\n","25/25 [==============================] - 23s 901ms/step - loss: 0.6502 - acc: 0.6825 - val_loss: 0.6369 - val_acc: 0.6354\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ytt4KxxBzoAr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"b4f28644-c6a4-4456-bfad-e26a4d94cbeb","executionInfo":{"status":"ok","timestamp":1582462634950,"user_tz":0,"elapsed":868,"user":{"displayName":"Giles Billenness","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcSh_UVvHR4Bkj3v8M_6HXbEMW2CdHL9XqNWjpbQ=s64","userId":"01010524810359179053"}}},"source":["from keras.preprocessing import image\n","import numpy as np\n","# from keras.models import load_model\n","# testmodel = create\n","# model = load_model('model_saved.h5')\n","\n","# predicting images\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_CATS/small/cat.5730.jpg', target_size=(img_width, img_height))\n","img\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_CATS/small/cat.5731.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_CATS/small/cat.5732.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_CATS/small/cat.5733.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_CATS/small/cat.5734.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","# ----------------------------------------------------\n","#-----------------------------------------------------\n","\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_DOGS/small/dog.12288.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_DOGS/small/dog.12289.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_DOGS/small/dog.12290.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","\n","# ----------------------------------------------------\n","img = image.load_img('drive/My Drive/Hackathon/cats&dogs/TEST_TEST_DOGS/small/dog.12291.jpg', target_size=(img_width, img_height))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","images = np.vstack([x])\n","classes = model.predict_classes(images, batch_size=10)\n","print(classes)\n","# ----------------------------------------------------"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[1]]\n","[[0]]\n","[[1]]\n","[[0]]\n","[[1]]\n","[[1]]\n","[[1]]\n","[[1]]\n","[[1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c1H-PmiutipT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}